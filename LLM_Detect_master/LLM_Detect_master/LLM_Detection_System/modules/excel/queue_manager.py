#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Excelè´¨é‡å·¥å•æ£€æµ‹é˜Ÿåˆ—ç®¡ç†æ¨¡å—
å®ç°çº¿ç¨‹å®‰å…¨çš„FIFOé˜Ÿåˆ—ï¼Œæ”¯æŒæ‰¹é‡å·¥å•çš„å¼‚æ­¥AIæ£€æµ‹å¤„ç†
"""

import threading
import queue
import time
import sys
import json
from typing import Dict, Optional, List, Any
from flask import current_app
from modules.excel.processor import Processor
from modules.excel.models import WorkorderData
from modules.auth import db
import traceback
import requests


class ExcelQueueManager:
    """Excelè´¨é‡å·¥å•æ£€æµ‹é˜Ÿåˆ—ç®¡ç†å™¨

    ç‰¹æ€§ï¼š
    - çº¿ç¨‹å®‰å…¨çš„FIFOé˜Ÿåˆ—
    - æ”¯æŒæ‰¹é‡å·¥å•æ£€æµ‹
    - è‡ªåŠ¨æ›´æ–°æ•°æ®åº“çŠ¶æ€
    - æ”¯æŒä»»åŠ¡çŠ¶æ€æŸ¥è¯¢
    - é”™è¯¯æ¢å¤æœºåˆ¶
    """

    def __init__(self, app=None):
        """åˆå§‹åŒ–é˜Ÿåˆ—ç®¡ç†å™¨

        Args:
            app: Flaskåº”ç”¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        """
        self.task_queue = queue.Queue()  # ä»»åŠ¡é˜Ÿåˆ—
        self.current_task = None  # å½“å‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡
        self.task_status = {}  # ä»»åŠ¡çŠ¶æ€å­—å…¸ {filename: status}
        self.task_results = {}  # ä»»åŠ¡ç»“æœå­—å…¸ {filename: {csv_filename, excel_filename}}
        self.lock = threading.Lock()  # çº¿ç¨‹é”
        self.worker_thread = None  # å·¥ä½œçº¿ç¨‹
        self.is_running = False  # è¿è¡ŒçŠ¶æ€æ ‡å¿—
        self.app = app  # Flaskåº”ç”¨å®ä¾‹
        self.processor = None  # Excelå¤„ç†å™¨å®ä¾‹

    @staticmethod
    def _fetch_token() -> str:
        """è°ƒç”¨å¤–éƒ¨ç™»å½•æ¥å£è·å– access_tokenã€‚"""
        url = "http://qmstest.angelgroup.com.cn:8080/ssoServer/oauth/login"
        headers = {
            "Authorization": "Basic cXVhbGl0eURhdGE6JDJhJDEwJGZDOU40WUxOWUlCLzgyM3ZQcjd2b2U3dWtndUtHSkRNYzdya210UmkxeHVCQ0lZZUcwMkJX",
            "Content-Type": "application/json",
        }
        payload = {
            "username": "ai",
            "password": "Ai@2025."
        }

        resp = requests.post(url, headers=headers, json=payload, timeout=30)
        resp.raise_for_status()

        try:
            data = resp.json()
        except ValueError:
            raise RuntimeError("ç™»å½•æ¥å£è¿”å›éJSON")

        token = (
            data.get("access_token")
            or data.get("token")
            or (data.get("data", {}) if isinstance(data, dict) else {}).get("access_token")
        )

        if not token:
            raise RuntimeError("ç™»å½•æ¥å£æœªè¿”å› access_token")

        return token

    @staticmethod
    def _submit_judgment(access_token: str, payload: Any) -> Dict:
        """æäº¤å·¥å•åˆ¤å®šæ•°æ®åˆ°å¤–éƒ¨æ¥å£ã€‚"""
        url = "http://qmstest.angelgroup.com.cn:8080/qualityDataAnalysis/baseData/crmMaintenanceData/aiSubmitJudgment"
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json",
        }

        resp = requests.post(url, headers=headers, json=payload, timeout=30)
        resp.raise_for_status()

        try:
            return resp.json()
        except ValueError:
            return {"raw": resp.text}
        
    def start(self):
        """å¯åŠ¨é˜Ÿåˆ—å¤„ç†çº¿ç¨‹"""
        if not self.is_running:
            self.is_running = True
            self.worker_thread = threading.Thread(target=self._process_queue, daemon=True)
            self.worker_thread.start()
            print("âœ… Excelæ£€æµ‹é˜Ÿåˆ—ç®¡ç†å™¨å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢é˜Ÿåˆ—å¤„ç†çº¿ç¨‹"""
        self.is_running = False
        if self.worker_thread:
            self.worker_thread.join(timeout=5)
        print("â¹ï¸  Excelæ£€æµ‹é˜Ÿåˆ—ç®¡ç†å™¨å·²åœæ­¢")
    
    def add_task(self, filename: str, filepath: str, batch_size: int = 50) -> bool:
        """æ·»åŠ æ£€æµ‹ä»»åŠ¡åˆ°é˜Ÿåˆ—
        
        Args:
            filename: æ•°æ®åº“ä¸­çš„å”¯ä¸€æ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
            filepath: å®é™…ä¸Šä¼ çš„Excelæ–‡ä»¶è·¯å¾„
            batch_size: æ¯æ‰¹å¤„ç†çš„å·¥å•æ•°é‡
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        try:
            with self.lock:
                # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                current_status = self.task_status.get(filename)
                
                # å¦‚æœä»»åŠ¡æ­£åœ¨å¤„ç†ä¸­æˆ–æ’é˜Ÿä¸­ï¼Œæ‹’ç»é‡å¤æ·»åŠ 
                if current_status in ['pending', 'processing']:
                    print(f"âš ï¸  ä»»åŠ¡æ­£åœ¨å¤„ç†ä¸­: {filename}, çŠ¶æ€: {current_status}")
                    return False
                
                # å¦‚æœä»»åŠ¡å·²å®Œæˆæˆ–å¤±è´¥ï¼Œå…è®¸é‡æ–°æ·»åŠ ï¼ˆæ¸…ç†æ—§çŠ¶æ€ï¼‰
                if current_status in ['completed', 'failed']:
                    print(f"ğŸ”„ æ¸…ç†æ—§ä»»åŠ¡çŠ¶æ€: {filename}, æ—§çŠ¶æ€: {current_status}")
                    # æ¸…ç†æ—§çš„ç»“æœç¼“å­˜
                    self.task_results.pop(filename, None)
                
                # æ·»åŠ åˆ°é˜Ÿåˆ—
                task = {
                    'filename': filename,
                    'filepath': filepath,
                    'batch_size': batch_size,
                    'added_time': time.time()
                }
                self.task_queue.put(task)
                self.task_status[filename] = 'pending'
                
                queue_size = self.task_queue.qsize()
                print(f"âœ… Excelæ£€æµ‹ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—: {filename}, é˜Ÿåˆ—é•¿åº¦: {queue_size}")
                return True
                
        except Exception as e:
            print(f"âŒ æ·»åŠ ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False
    
    def get_task_status(self, filename: str) -> Optional[str]:
        """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
        
        Args:
            filename: æ–‡ä»¶å
            
        Returns:
            str: çŠ¶æ€ (pending/processing/completed/failed) æˆ– None
        """
        with self.lock:
            return self.task_status.get(filename)
    
    def get_task_result(self, filename: str) -> Optional[Dict]:
        """æŸ¥è¯¢ä»»åŠ¡ç»“æœï¼ˆåŒ…å«ç”Ÿæˆçš„æ–‡ä»¶åï¼‰
        
        Args:
            filename: æ–‡ä»¶å
            
        Returns:
            dict: ç»“æœä¿¡æ¯ {csv_filename, excel_filename} æˆ– None
        """
        with self.lock:
            return self.task_results.get(filename)
    
    def get_queue_info(self) -> Dict:
        """è·å–é˜Ÿåˆ—ä¿¡æ¯
        
        Returns:
            dict: é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
        """
        with self.lock:
            return {
                'queue_size': self.task_queue.qsize(),
                'current_task': self.current_task,
                'total_tasks': len(self.task_status),
                'is_running': self.is_running
            }
    
    def _process_queue(self):
        """é˜Ÿåˆ—å¤„ç†ä¸»å¾ªç¯ï¼ˆåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
        print("ğŸ”„ Excelæ£€æµ‹é˜Ÿåˆ—å¤„ç†çº¿ç¨‹å·²å¯åŠ¨")
        
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼ˆè¶…æ—¶1ç§’ï¼Œé¿å…é˜»å¡ï¼‰
                try:
                    task = self.task_queue.get(timeout=1)
                except queue.Empty:
                    continue
                
                filename = task['filename']
                filepath = task['filepath']
                batch_size = task.get('batch_size', 5)
                max_workers = task.get('max_workers', 10)
                batch_size = 1

                # æ›´æ–°å½“å‰ä»»åŠ¡
                with self.lock:
                    self.current_task = filename
                    self.task_status[filename] = 'processing'
                
                print(f"ğŸ” å¼€å§‹æ£€æµ‹Excelä»»åŠ¡: {filename}")
                print(f"ğŸ“Š æ‰¹é‡å¤„ç†å¤§å°: {batch_size} æ¡/æ‰¹")
                print(f"ğŸ“Š æœ€å¤§çº¿ç¨‹æ•°: {max_workers} ")

                # æ‰§è¡Œæ£€æµ‹
                start_time = time.time()
                result = self._execute_inspection(filename, filepath, batch_size, max_workers)
                duration = time.time() - start_time
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                with self.lock:
                    if result['success']:
                        self.task_status[filename] = 'completed'
                        print(f"âœ… Excelæ£€æµ‹å®Œæˆ: {filename}, è€—æ—¶: {duration:.2f}ç§’, å¤„ç†: {result.get('processed_count', 0)}æ¡")
                    else:
                        self.task_status[filename] = 'failed'
                        print(f"âŒ Excelæ£€æµ‹å¤±è´¥: {filename}, åŸå› : {result.get('error', 'æœªçŸ¥')}")
                    
                    self.current_task = None
                
                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                self.task_queue.task_done()
                
            except Exception as e:
                print(f"âŒ é˜Ÿåˆ—å¤„ç†å¼‚å¸¸: {str(e)}")
                print(traceback.format_exc())
                with self.lock:
                    if self.current_task:
                        self.task_status[self.current_task] = 'failed'
                    self.current_task = None
        
        print("â¹ï¸  Excelæ£€æµ‹é˜Ÿåˆ—å¤„ç†çº¿ç¨‹å·²é€€å‡º")
    
    def _execute_inspection(self, filename: str, filepath: str, batch_size: int, max_workers: int) -> Dict:
        """æ‰§è¡ŒExcelæ£€æµ‹å¹¶æ›´æ–°æ•°æ®åº“
        
        Args:
            filename: æ•°æ®åº“ä¸­çš„æ–‡ä»¶å
            filepath: Excelæ–‡ä»¶è·¯å¾„
            batch_size: æ‰¹é‡å¤„ç†å¤§å°
            
        Returns:
            dict: æ£€æµ‹ç»“æœ
        """
        try:
            # åˆå§‹åŒ–å¤„ç†å™¨
            if not self.processor:
                self.processor = Processor()
            
            # å›ºå®šçš„è®­ç»ƒå·¥å•è·¯å¾„
            if self.app:
                with self.app.app_context():
                    training_file = f"{self.app.root_path}/data/è®­ç»ƒæ•°æ®æ–°100æ¡.xlsx"
            else:
                training_file = "data/è®­ç»ƒæ•°æ®æ–°100æ¡.xlsx"
            
            print(f"ğŸ“š ä½¿ç”¨è®­ç»ƒæ–‡ä»¶: {training_file}")
            
            # è°ƒç”¨åˆ†æ‰¹å¤„ç†æ–¹æ³•ï¼ˆå¿…é¡»åœ¨åº”ç”¨ä¸Šä¸‹æ–‡ä¸­ï¼‰
            print(f"ğŸš€ å¼€å§‹åˆ†æ‰¹AIè´¨é‡åˆ¤æ–­...")
            
            if self.app:
                with self.app.app_context():
                    quality_result, usage_stats, processed_count = self.processor.batch_process_quality_from_db(
                        filename=filename,
                        training_excel=training_file,
                        batch_size=batch_size,
                        max_workers=max_workers
                    )
            else:
                error_msg = "Flaskåº”ç”¨ä¸Šä¸‹æ–‡æœªåˆå§‹åŒ–"
                print(f"âŒ {error_msg}")
                return {'success': False, 'error': error_msg}
            
            if not quality_result:
                error_msg = "åˆ†æ‰¹å¤„ç†æœªè¿”å›ç»“æœ"
                print(f"âŒ {error_msg}")
                return {'success': False, 'error': error_msg}
            
            print(f"âœ… AIåˆ¤æ–­å®Œæˆï¼Œå…±å¤„ç†: {processed_count}æ¡è®°å½•")
            
            # è§£æCSVç»“æœå¹¶å›å†™æ•°æ®åº“
            import pandas as pd
            from io import StringIO
            
            try:
                # æ£€æŸ¥CSVæ˜¯å¦æœ‰æ­£ç¡®çš„è¡¨å¤´
                lines = quality_result.strip().split('\n')
                if not lines:
                    error_msg = "CSVç»“æœä¸ºç©º"
                    print(f"âŒ {error_msg}")
                    return {'success': False, 'error': error_msg}
                
                # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯è¡¨å¤´
                first_line = lines[0]
                expected_header = 'å·¥å•å•å·,å·¥å•æ€§è´¨,åˆ¤å®šä¾æ®'
                
                if not first_line.startswith('å·¥å•å•å·'):
                    print(f"âš ï¸  è­¦å‘Š: CSVç¼ºå°‘è¡¨å¤´ï¼Œè‡ªåŠ¨æ·»åŠ ")
                    # æ·»åŠ æ ‡å‡†è¡¨å¤´
                    standard_header = 'å·¥å•å•å·,å·¥å•æ€§è´¨,åˆ¤å®šä¾æ®,ä¿å†…ä¿å¤–,æ‰¹æ¬¡å…¥åº“æ—¥æœŸ,å®‰è£…æ—¥æœŸ,è´­æœºæ—¥æœŸ,äº§å“åç§°,å¼€å‘ä¸»ä½“,æ•…éšœéƒ¨ä½åç§°,æ•…éšœç»„,æ•…éšœç±»åˆ«,æœåŠ¡é¡¹ç›®æˆ–æ•…éšœç°è±¡,ç»´ä¿®æ–¹å¼,æ—§ä»¶åç§°,æ–°ä»¶åç§°,æ¥ç”µå†…å®¹,ç°åœºè¯Šæ–­æ•…éšœç°è±¡,å¤„ç†æ–¹æ¡ˆç®€è¿°æˆ–å¤‡æ³¨'
                    quality_result = standard_header + '\n' + quality_result
                
                
                df_result = pd.read_csv(StringIO(quality_result), dtype=str, encoding='utf-8')
                print(f"ğŸ“ CSVç»“æœåŒ…å« {len(df_result)} è¡Œæ•°æ®")
                
                # è°ƒè¯•ï¼šæ‰“å°CSVçš„åˆ—å
                print(f"ğŸ” CSVåˆ—å: {df_result.columns.tolist()}")
                
                # è°ƒè¯•ï¼šæ‰“å°ç¬¬ä¸€è¡Œæ•°æ®
                if len(df_result) > 0:
                    first_row = df_result.iloc[0]
                    print(f"ğŸ” ç¬¬ä¸€è¡Œæ•°æ®ç¤ºä¾‹:")
                    print(f"   å·¥å•å•å·: '{first_row.get('å·¥å•å•å·', 'N/A')}'")
                    print(f"   å·¥å•æ€§è´¨: '{first_row.get('å·¥å•æ€§è´¨', 'N/A')}'")
                
                # éªŒè¯æ•°æ®è¡Œæ•°
                if len(df_result) != processed_count:
                    print(f"âš ï¸  è­¦å‘Š: CSVè¡Œæ•°({len(df_result)})ä¸å¤„ç†è®°å½•æ•°({processed_count})ä¸ä¸€è‡´")
                    print(f"   å¯èƒ½åŸå› : AIè¾“å‡ºä¸å®Œæ•´æˆ–åŒ…å«é¢å¤–çš„ç©ºè¡Œ")
                
            except Exception as e:
                error_msg = f"CSVè§£æå¤±è´¥: {str(e)}"
                print(f"âŒ {error_msg}")
                return {'success': False, 'error': error_msg}
            
            # å›å†™å·¥å•æ€§è´¨å’Œåˆ¤å®šä¾æ®åˆ°æ•°æ®åº“
            updated_count = 0
            not_found_count = 0
            records_payload = []
            if self.app:
                with self.app.app_context():
                    for index, row in df_result.iterrows():
                        work_alone = str(row.get('å·¥å•å•å·', '')).strip()
                        work_order_nature = str(row.get('å·¥å•æ€§è´¨', '')).strip()
                        judgment_basis = str(row.get('åˆ¤å®šä¾æ®', '')).strip()

                        if not work_alone or work_alone == 'nan':
                            continue
                        
                        # è°ƒè¯•ï¼šæ‰“å°æŸ¥è¯¢æ¡ä»¶ï¼ˆåªæ‰“å°å‰3æ¡ï¼‰
                        if index < 3:
                            print(f"ğŸ” æŸ¥è¯¢æ¡ä»¶[{index}]: workAlone='{work_alone}', filename='{filename}'")
                        
                        # æŸ¥è¯¢æ•°æ®åº“è®°å½• - ä½¿ç”¨ .all() è·å–æ‰€æœ‰åŒ¹é…çš„è®°å½•
                        records = WorkorderData.query.filter_by(
                            workAlone=work_alone,
                            filename=filename
                        ).all()

                        if records:
                            records_payload.append({
                                "workAlone": work_alone,
                                "workOrderNature": work_order_nature,
                                "judgmentBasis": judgment_basis
                            })
                            # æ›´æ–°æ‰€æœ‰åŒ¹é…çš„è®°å½•
                            for record in records:
                                record.workOrderNature = work_order_nature if work_order_nature and work_order_nature != 'nan' else None
                                record.judgmentBasis = judgment_basis if judgment_basis and judgment_basis != 'nan' else None
                                updated_count += 1
                            
                            if index < 3:
                                print(f"   âœ… æ‰¾åˆ° {len(records)} æ¡è®°å½•ï¼Œå·²å…¨éƒ¨æ›´æ–°")
                        else:
                            not_found_count += 1
                            if index < 3:
                                print(f"   âŒ æœªæ‰¾åˆ°è®°å½•")
                    
                    # æäº¤æ›´æ–°
                    db.session.commit()
                    print(f"ğŸ’¾ æ•°æ®åº“æ›´æ–°å®Œæˆ: æˆåŠŸæ›´æ–° {updated_count} æ¡è®°å½•")
                    
                    if not_found_count > 0:
                        print(f"âš ï¸  æœªæ‰¾åˆ° {not_found_count} æ¡è®°å½•")
            
            # å°†åˆ¤å®šç»“æœä¸ŠæŠ¥åˆ°å¤–éƒ¨æ¥å£
            try:
                token = self._fetch_token()
                # submit_resp = self._submit_judgment(token, records_payload)
                # print(f"ğŸš€ å·²æäº¤åˆ¤å®šç»“æœ {len(records_payload)}æ¡ åˆ°å¤–éƒ¨æ¥å£")
                print("åˆ¤å®šç»“æœæœªæäº¤åˆ°å¤–éƒ¨æ¥å£ï¼ˆæ­¤å¤„ä»£ç è¢«æ³¨é‡Šæ‰ä»¥é˜²æ­¢å®é™…è°ƒç”¨ï¼‰")
                # print(json.dumps(submit_resp, ensure_ascii=False, indent=2) if isinstance(submit_resp, dict) else submit_resp)
            except Exception as e:
                print(f"âš ï¸  æäº¤åˆ¤å®šç»“æœ {len(records_payload)}æ¡ åˆ°å¤–éƒ¨æ¥å£å¤±è´¥: {e}")

            # ========================================
            # æ–°å¢ï¼šç”ŸæˆExcelç»“æœæ–‡ä»¶
            # ========================================
            print("ğŸ”¨ æ­£åœ¨ç”ŸæˆExcelç»“æœæ–‡ä»¶...")

            try:
                if self.app:
                    with self.app.app_context():
                        from modules.excel.models import WorkorderUselessdata1, WorkorderUselessdata2

                        # 1. ä¸€æ¬¡æ€§æŸ¥è¯¢æ‰€æœ‰ä¸»è¡¨è®°å½•
                        records = WorkorderData.query.filter_by(filename=filename).all()

                        if not records:
                            print(f"âš ï¸  æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ {filename} çš„è®°å½•")
                            return {
                                'success': True,
                                'processed_count': processed_count,
                                'updated_count': updated_count,
                                'not_found_count': not_found_count,
                                'excel_generated': False,
                                'total_rows': 0
                            }

                        # 2. æå–æ‰€æœ‰å·¥å•å·ç”¨äºæ‰¹é‡æŸ¥è¯¢
                        work_alone_list = [record.workAlone for record in records if record.workAlone]
                        print(f"ğŸ“Š å¼€å§‹å¤„ç† {len(work_alone_list)} æ¡å·¥å•è®°å½•")

                        # 3. æ‰¹é‡æŸ¥è¯¢ WorkorderUselessdata1 è¡¨
                        u1_records = WorkorderUselessdata1.query.filter(
                            WorkorderUselessdata1.filename == filename,
                            WorkorderUselessdata1.workAlone.in_(work_alone_list)
                        ).all()

                        # æ„å»º u1 çš„æ˜ å°„å­—å…¸ {workAlone: u1_record}
                        u1_dict = {u.workAlone: u for u in u1_records}

                        # 4. æ‰¹é‡æŸ¥è¯¢ WorkorderUselessdata2 è¡¨
                        u2_records = WorkorderUselessdata2.query.filter(
                            WorkorderUselessdata2.filename == filename,
                            WorkorderUselessdata2.workAlone.in_(work_alone_list)
                        ).all()

                        # æ„å»º u2 çš„æ˜ å°„å­—å…¸ {workAlone: u2_record}
                        u2_dict = {u.workAlone: u for u in u2_records}

                        print(f"âœ… æ‰¹é‡æŸ¥è¯¢å®Œæˆ: u1è®°å½•={len(u1_records)}, u2è®°å½•={len(u2_records)}")

                        # 5. å®šä¹‰19ä¸ªå­—æ®µ
                        expected_columns = [
                            'å·¥å•å•å·', 'å·¥å•æ€§è´¨', 'åˆ¤å®šä¾æ®', 'ä¿å†…ä¿å¤–', 'æ‰¹æ¬¡å…¥åº“æ—¥æœŸ', 'å®‰è£…æ—¥æœŸ',
                            'è´­æœºæ—¥æœŸ', 'äº§å“åç§°', 'å¼€å‘ä¸»ä½“', 'æ•…éšœéƒ¨ä½åç§°', 'æ•…éšœç»„', 'æ•…éšœç±»åˆ«',
                            'æœåŠ¡é¡¹ç›®æˆ–æ•…éšœç°è±¡', 'ç»´ä¿®æ–¹å¼', 'æ—§ä»¶åç§°', 'æ–°ä»¶åç§°', 'æ¥ç”µå†…å®¹',
                            'ç°åœºè¯Šæ–­æ•…éšœç°è±¡', 'å¤„ç†æ–¹æ¡ˆç®€è¿°æˆ–å¤‡æ³¨'
                        ]

                        # 6. ä¼˜åŒ–åçš„è§„èŒƒåŒ–å‡½æ•°ï¼ˆé¢„å…ˆç¼–è¯‘æ­£åˆ™ï¼Œå‡å°‘å‡½æ•°è°ƒç”¨å¼€é”€ï¼‰
                        def norm_fast(v):
                            """å¿«é€Ÿè§„èŒƒåŒ–å‡½æ•°"""
                            if v is None:
                                return ''
                            if isinstance(v, str) and v == 'None':
                                return ''
                            if isinstance(v, float) and pd.isna(v):
                                return ''
                            return str(v)

                        # 7. ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼å¿«é€Ÿæ„å»ºæ•°æ®
                        import time
                        start_time = time.time()

                        # é¢„å®šä¹‰å­—æ®µè·å–å‡½æ•°ï¼Œå‡å°‘å¾ªç¯ä¸­çš„å±æ€§æŸ¥æ‰¾
                        temp_data = []
                        for record in records:
                            work_alone = record.workAlone

                            # ä»å­—å…¸ä¸­è·å–å…³è”è®°å½•ï¼ˆO(1)æ—¶é—´å¤æ‚åº¦ï¼‰
                            u1 = u1_dict.get(work_alone)
                            u2 = u2_dict.get(work_alone)

                            # æ„å»ºè¡Œæ•°æ® - ç›´æ¥èµ‹å€¼ï¼Œå‡å°‘ä¸­é—´å˜é‡
                            row_data = [
                                # å·¥å•å•å·
                                norm_fast(work_alone),
                                # å·¥å•æ€§è´¨
                                norm_fast(record.workOrderNature),
                                # åˆ¤å®šä¾æ®
                                norm_fast(record.judgmentBasis),
                                # ä¿å†…ä¿å¤–
                                norm_fast(u1.internalExternalInsurance if u1 else ''),
                                # æ‰¹æ¬¡å…¥åº“æ—¥æœŸ
                                norm_fast(u1.batchWarehousingDate if u1 else ''),
                                # å®‰è£…æ—¥æœŸ
                                norm_fast(u1.installDate if u1 else ''),
                                # è´­æœºæ—¥æœŸ
                                norm_fast(u1.purchaseDate if u1 else ''),
                                # äº§å“åç§°
                                norm_fast(u1.productName if u1 else ''),
                                # å¼€å‘ä¸»ä½“
                                norm_fast(u1.developmentSubject if u1 else ''),
                                # æ•…éšœéƒ¨ä½åç§°
                                norm_fast(record.replacementPartName),
                                # æ•…éšœç»„
                                norm_fast(record.faultGroup),
                                # æ•…éšœç±»åˆ«
                                norm_fast(record.faultClassification),
                                # æœåŠ¡é¡¹ç›®æˆ–æ•…éšœç°è±¡
                                norm_fast(record.faultPhenomenon),
                                # ç»´ä¿®æ–¹å¼
                                norm_fast(u2.maintenanceMode if u2 else ''),
                                # æ—§ä»¶åç§°
                                norm_fast(u2.oldPartName if u2 else ''),
                                # æ–°ä»¶åç§°
                                norm_fast(u2.newPartName if u2 else ''),
                                # æ¥ç”µå†…å®¹
                                norm_fast(record.callContent),
                                # ç°åœºè¯Šæ–­æ•…éšœç°è±¡
                                norm_fast(record.onsiteFaultPhenomenon),
                                # å¤„ç†æ–¹æ¡ˆç®€è¿°æˆ–å¤‡æ³¨
                                norm_fast(record.remarks)
                            ]

                            temp_data.append(row_data)

                        build_time = time.time() - start_time
                        print(f"âš¡ æ•°æ®æ„å»ºå®Œæˆ: {build_time:.3f}ç§’, {len(temp_data)}è¡Œ")

                        # 8. ä½¿ç”¨ä¼˜åŒ–çš„æ–¹å¼åˆ›å»ºDataFrame
                        start_time = time.time()
                        df_result = pd.DataFrame(temp_data, columns=expected_columns)
                        df_time = time.time() - start_time
                        print(f"ğŸ“„ DataFrameåˆ›å»º: {df_time:.3f}ç§’")

                        # 9. ç”Ÿæˆç»“æœæ–‡ä»¶å
                        import os
                        if filename.lower().endswith('.xlsx'):
                            base_filename = filename[:-5]
                            excel_filename = f"quality_result_{filename}"
                            csv_filename = f"quality_result_{base_filename}.csv"
                        else:
                            excel_filename = f"quality_result_{filename}.xlsx"
                            csv_filename = f"quality_result_{filename}.csv"

                        # 10. ä¿å­˜æ–‡ä»¶
                        results_folder = self.app.config.get('RESULTS_FOLDER', 'results')
                        os.makedirs(results_folder, exist_ok=True)

                        # ä¿å­˜Excelæ–‡ä»¶ï¼ˆä½¿ç”¨æ›´å¿«çš„å¼•æ“ï¼‰
                        excel_start = time.time()
                        excel_filepath = os.path.join(results_folder, excel_filename)
                        df_result.to_excel(
                            excel_filepath,
                            index=False,
                            engine='openpyxl'  # æ˜ç¡®æŒ‡å®šå¼•æ“
                        )
                        excel_time = time.time() - excel_start
                        print(f"ğŸ’¾ Excelä¿å­˜: {excel_time:.3f}ç§’")
                        print(f"âœ… Excelç»“æœæ–‡ä»¶: {excel_filename}")

                        # ä¿å­˜CSVæ–‡ä»¶
                        csv_start = time.time()
                        csv_filepath = os.path.join(results_folder, csv_filename)
                        df_result.to_csv(csv_filepath, index=False, encoding='utf-8')
                        csv_time = time.time() - csv_start
                        print(f"ğŸ’¾ CSVä¿å­˜: {csv_time:.3f}ç§’")
                        print(f"âœ… CSVç»“æœæ–‡ä»¶: {csv_filename}")

                        # 11. ä¿å­˜ç»“æœä¿¡æ¯
                        with self.lock:
                            self.task_results[filename] = {
                                'excel_filename': excel_filename,
                                'csv_filename': csv_filename,
                                'excel_filepath': excel_filepath,
                                'csv_filepath': csv_filepath,
                                'rows_processed': len(df_result),
                                'completed_count': updated_count,
                                'total_count': processed_count
                            }

                        print(
                            f"ğŸ¯ å¤„ç†å®Œæˆ: æ€»è®¡{len(df_result)}è¡Œ, è€—æ—¶{build_time + df_time + excel_time + csv_time:.3f}ç§’")

            except Exception as e:
                print(f"âš ï¸  ç”ŸæˆExcelç»“æœæ–‡ä»¶å¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()

            return {
                'success': True,
                'processed_count': processed_count,
                'updated_count': updated_count,
                'not_found_count': not_found_count
            }
            
        except Exception as e:
            error_msg = f"æ£€æµ‹å¼‚å¸¸: {str(e)}"
            print(f"âŒ {error_msg}")
            print(traceback.format_exc())
            return {'success': False, 'error': error_msg}


# å…¨å±€é˜Ÿåˆ—ç®¡ç†å™¨å®ä¾‹
_queue_manager = None


def get_queue_manager(app=None) -> ExcelQueueManager:
    """è·å–å…¨å±€é˜Ÿåˆ—ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Args:
        app: Flaskåº”ç”¨å®ä¾‹ï¼ˆé¦–æ¬¡è°ƒç”¨æ—¶å¿…é¡»æä¾›ï¼‰

    Returns:
        ExcelQueueManager: é˜Ÿåˆ—ç®¡ç†å™¨å®ä¾‹
    """
    global _queue_manager
    if _queue_manager is None:
        if app is None:
            # å°è¯•ä»Flaskä¸Šä¸‹æ–‡è·å–åº”ç”¨å®ä¾‹
            try:
                app = current_app._get_current_object()
            except RuntimeError:
                raise RuntimeError(
                    "é¦–æ¬¡è°ƒç”¨ get_queue_manager() æ—¶å¿…é¡»æä¾› Flask åº”ç”¨å®ä¾‹ï¼Œ"
                    "æˆ–åœ¨ Flask åº”ç”¨ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨"
                )
        _queue_manager = ExcelQueueManager(app)
        _queue_manager.start()
    return _queue_manager
