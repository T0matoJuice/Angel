#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´æµç¨‹æµ‹è¯•è„šæœ¬ - åŒ…å«ä¸Šä¼ å’Œæ£€æµ‹ç›‘æ§
æµ‹è¯•æµç¨‹ï¼šä¸Šä¼  â†’ å…¥åº“ â†’ AIæ£€æµ‹ â†’ ç»“æœéªŒè¯
"""

import requests
import json
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import random


# çœŸå®çš„å·¥å•æ•°æ®ï¼ˆç”¨æˆ·æä¾›ï¼‰
REAL_WORKORDER_DATA = {
    "workorders": [
        {"å·¥å•æ€§è´¨":None,"å·¥å•å•å·":"WO0018329556","æ•…éšœç»„":"å‡€é¥®æœº","æ–°ä»¶åç§°":None,"æ¥ç”µå†…å®¹":None,"ä¿å†…ä¿å¤–":"ä¿å†…","æœåŠ¡é¡¹ç›®æˆ–æ•…éšœç°è±¡":None,"æ‰¹æ¬¡å…¥åº“æ—¥æœŸ":None,"æ•…éšœç±»åˆ«":"ç”µæ°”ç±»","å¤„ç†æ–¹æ¡ˆç®€è¿°æˆ–å¤‡æ³¨":"æ‰“å¼€å†°æ°´å¼€å…³","äº§å“åç§°":"å•†åŠ¡ç›´é¥®æœº ç«‹å¼åæ¸—é€å‹ç¼©æœºåˆ¶å†·å•†åŠ¡ç›´é¥®æœºAHR26-1030K1Y(ç™½è‰²+é“¶è‰²)","æ—§ä»¶åç§°":None,"ç°åœºè¯Šæ–­æ•…éšœç°è±¡":None,"è´­æœºæ—¥æœŸ":"2025-08-07","å¼€å‘ä¸»ä½“":None,"æ•…éšœéƒ¨ä½åç§°":"è··æ¿å¼€å…³ KCD11-1å¤§ç»¿","å®‰è£…æ—¥æœŸ":None,"ç»´ä¿®æ–¹å¼":"ä¸Šé—¨ç»´ä¿®","åˆ¤å®šä¾æ®":None},
        {"å·¥å•æ€§è´¨":None,"å·¥å•å•å·":"WO0018329558","æ•…éšœç»„":"å‡€é¥®æœº","æ–°ä»¶åç§°":None,"æ¥ç”µå†…å®¹":None,"ä¿å†…ä¿å¤–":"ä¿å†…","æœåŠ¡é¡¹ç›®æˆ–æ•…éšœç°è±¡":None,"æ‰¹æ¬¡å…¥åº“æ—¥æœŸ":None,"æ•…éšœç±»åˆ«":"ç”µæ°”ç±»","å¤„ç†æ–¹æ¡ˆç®€è¿°æˆ–å¤‡æ³¨":"ç»“å†°éœ€è¦æ›´æ¢æ¸©æ§","äº§å“åç§°":"å•†åŠ¡ç›´é¥®æœº ç«‹å¼åæ¸—é€å‹ç¼©æœºåˆ¶å†·å•†åŠ¡ç›´é¥®æœºAHR26-1030K1Y(ç™½è‰²+é“¶è‰²)","æ—§ä»¶åç§°":None,"ç°åœºè¯Šæ–­æ•…éšœç°è±¡":None,"è´­æœºæ—¥æœŸ":"2025-09-30","å¼€å‘ä¸»ä½“":None,"æ•…éšœéƒ¨ä½åç§°":"æ‰‹åŠ¨å¤ä½æ¸©æ§å™¨-HB 110â„ƒ","å®‰è£…æ—¥æœŸ":None,"ç»´ä¿®æ–¹å¼":"ä¸Šé—¨ç»´ä¿®","åˆ¤å®šä¾æ®":None},
        {"å·¥å•æ€§è´¨":None,"å·¥å•å•å·":"WO0018329559","æ•…éšœç»„":"å‡€é¥®æœº","æ–°ä»¶åç§°":None,"æ¥ç”µå†…å®¹":None,"ä¿å†…ä¿å¤–":"ä¿å¤–","æœåŠ¡é¡¹ç›®æˆ–æ•…éšœç°è±¡":None,"æ‰¹æ¬¡å…¥åº“æ—¥æœŸ":None,"æ•…éšœç±»åˆ«":"å¤–è§‚ç»“æ„ç±»","å¤„ç†æ–¹æ¡ˆç®€è¿°æˆ–å¤‡æ³¨":"å‹ç¼©æœºå¼‚å“æ— æ³•ç»´ä¿®","äº§å“åç§°":"å•†åŠ¡ç›´é¥®æœº ç«‹å¼åæ¸—é€å‹ç¼©æœºåˆ¶å†·å•†åŠ¡ç›´é¥®æœºAHR26-1030K1Y(ç™½è‰²+é“¶è‰²)","æ—§ä»¶åç§°":None,"ç°åœºè¯Šæ–­æ•…éšœç°è±¡":None,"è´­æœºæ—¥æœŸ":"2025-06-07","å¼€å‘ä¸»ä½“":None,"æ•…éšœéƒ¨ä½åç§°":"å‹ç¼©æœºå‹æ¿ 90*20*2(åŸè‰²)","å®‰è£…æ—¥æœŸ":None,"ç»´ä¿®æ–¹å¼":"ä¸Šé—¨ç»´ä¿®","åˆ¤å®šä¾æ®":None}
    ]
}


def upload_batch(url: str, batch_id: str, workorder_count: int = 3, token: str = None):
    """ä¸Šä¼ ä¸€ä¸ªæ‰¹æ¬¡"""
    data = {
        "unique_filename": batch_id,
        "filename": batch_id,
        "workorders": [],
        "account": "TEST_QMS"
    }
    
    for i in range(workorder_count):
        workorder = REAL_WORKORDER_DATA["workorders"][i % 3].copy()
        workorder["å·¥å•å•å·"] = f"TEST_{batch_id}_{i:04d}"
        data["workorders"].append(workorder)
    
    try:
        start_time = time.time()
        headers = {'Content-Type': 'application/json'}
        if token:
            headers['Authorization'] = f'Bearer {token}'
        
        response = requests.post(url, json=data, headers=headers, timeout=60)
        elapsed = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… æ‰¹æ¬¡ {batch_id}: æˆåŠŸ - {result.get('success_count', 0)}æ¡å…¥åº“ - è€—æ—¶{elapsed:.2f}ç§’")
            return True, elapsed, result, batch_id
        else:
            print(f"âŒ æ‰¹æ¬¡ {batch_id}: å¤±è´¥ - HTTP {response.status_code}")
            return False, elapsed, {'error': response.text[:100]}, batch_id
    
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡ {batch_id}: å¼‚å¸¸ - {str(e)}")
        return False, 0, {'error': str(e)}, batch_id


def check_queue_status(base_url: str, token: str = None):
    """æŸ¥è¯¢é˜Ÿåˆ—çŠ¶æ€"""
    url = f"{base_url}/excel/api/queue/info"
    headers = {'Content-Type': 'application/json'}
    if token:
        headers['Authorization'] = f'Bearer {token}'
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            return response.json()
        return None
    except:
        return None


def verify_detection_results(batch_id: str, base_url: str, token: str = None, expected_count: int = 0):
    """éªŒè¯æ£€æµ‹ç»“æœ"""
    url = f"{base_url}/excel/api/history"
    headers = {'Content-Type': 'application/json'}
    if token:
        headers['Authorization'] = f'Bearer {token}'
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        if response.status_code != 200:
            return None
        
        data = response.json()
        if not data.get('success'):
            return None
        
        records = data.get('records', [])
        batch_records = [r for r in records if r.get('filename') == batch_id]
        
        if not batch_records:
            return None
        
        total_count = len(batch_records)
        filled_count = sum(1 for r in batch_records if r.get('workOrderNature'))
        quality_count = sum(1 for r in batch_records if r.get('workOrderNature') == 'è´¨é‡å·¥å•')
        non_quality_count = sum(1 for r in batch_records if r.get('workOrderNature') == 'éè´¨é‡å·¥å•')
        
        return {
            'total_count': total_count,
            'filled_count': filled_count,
            'quality_count': quality_count,
            'non_quality_count': non_quality_count,
            'fill_rate': filled_count / total_count * 100 if total_count > 0 else 0
        }
        
    except:
        return None


def monitor_detection(batch_ids: list, base_url: str, token: str = None, 
                      max_wait_time: int = 600, check_interval: int = 10):
    """ç›‘æ§æ£€æµ‹è¿‡ç¨‹"""
    print("\n" + "=" * 80)
    print("ğŸ” å¼€å§‹ç›‘æ§AIæ£€æµ‹è¿‡ç¨‹")
    print("=" * 80)
    print(f"ğŸ“Š ç›‘æ§æ‰¹æ¬¡æ•°: {len(batch_ids)}")
    print(f"â° æœ€å¤§ç­‰å¾…æ—¶é—´: {max_wait_time}ç§’")
    print(f"ğŸ”„ æ£€æŸ¥é—´éš”: {check_interval}ç§’")
    print("=" * 80)
    
    start_time = time.time()
    last_queue_size = None
    completed_batches = set()
    
    while time.time() - start_time < max_wait_time:
        elapsed = time.time() - start_time
        
        # æŸ¥è¯¢é˜Ÿåˆ—çŠ¶æ€
        queue_info = check_queue_status(base_url, token)
        if queue_info:
            queue_size = queue_info.get('queue_size', 0)
            current_task = queue_info.get('current_task', '')
            
            if queue_size != last_queue_size:
                print(f"\n[{elapsed:.0f}s] é˜Ÿåˆ—çŠ¶æ€:")
                print(f"   - é˜Ÿåˆ—é•¿åº¦: {queue_size}")
                print(f"   - å½“å‰ä»»åŠ¡: {current_task or 'æ— '}")
                last_queue_size = queue_size
        
        # æ£€æŸ¥æ¯ä¸ªæ‰¹æ¬¡çš„æ£€æµ‹ç»“æœ
        for batch_id in batch_ids:
            if batch_id in completed_batches:
                continue
            
            result = verify_detection_results(batch_id, base_url, token)
            if result and result['fill_rate'] >= 99:
                completed_batches.add(batch_id)
                print(f"âœ… æ‰¹æ¬¡ {batch_id}: æ£€æµ‹å®Œæˆ ({result['filled_count']}/{result['total_count']})")
        
        # å¦‚æœæ‰€æœ‰æ‰¹æ¬¡éƒ½å®Œæˆäº†
        if len(completed_batches) == len(batch_ids):
            print(f"\nğŸ‰ æ‰€æœ‰æ‰¹æ¬¡æ£€æµ‹å®Œæˆï¼æ€»è€—æ—¶ {elapsed:.0f} ç§’")
            break
        
        # æ˜¾ç¤ºè¿›åº¦
        progress = len(completed_batches) / len(batch_ids) * 100
        print(f"[{elapsed:.0f}s] æ£€æµ‹è¿›åº¦: {len(completed_batches)}/{len(batch_ids)} ({progress:.1f}%)", end='\r')
        
        time.sleep(check_interval)
    
    # æœ€ç»ˆç»Ÿè®¡
    print("\n\n" + "=" * 80)
    print("ğŸ“Š æ£€æµ‹ç»“æœç»Ÿè®¡")
    print("=" * 80)
    
    total_workorders = 0
    total_filled = 0
    total_quality = 0
    total_non_quality = 0
    
    for batch_id in batch_ids:
        result = verify_detection_results(batch_id, base_url, token)
        if result:
            total_workorders += result['total_count']
            total_filled += result['filled_count']
            total_quality += result['quality_count']
            total_non_quality += result['non_quality_count']
            
            print(f"\næ‰¹æ¬¡: {batch_id}")
            print(f"   - æ€»å·¥å•æ•°: {result['total_count']}")
            print(f"   - å·²åˆ¤å®šæ•°: {result['filled_count']} ({result['fill_rate']:.1f}%)")
            print(f"   - è´¨é‡å·¥å•: {result['quality_count']}")
            print(f"   - éè´¨é‡å·¥å•: {result['non_quality_count']}")
    
    overall_fill_rate = total_filled / total_workorders * 100 if total_workorders > 0 else 0
    
    print(f"\næ€»è®¡:")
    print(f"   - æ€»å·¥å•æ•°: {total_workorders}")
    print(f"   - å·²åˆ¤å®šæ•°: {total_filled} ({overall_fill_rate:.1f}%)")
    print(f"   - è´¨é‡å·¥å•: {total_quality}")
    print(f"   - éè´¨é‡å·¥å•: {total_non_quality}")
    
    if overall_fill_rate >= 99:
        print(f"\nğŸ¯ è¯„ä¼°: âœ… ä¼˜ç§€ï¼æ£€æµ‹å®Œæˆåº¦ {overall_fill_rate:.1f}%")
    elif overall_fill_rate >= 90:
        print(f"\nğŸ¯ è¯„ä¼°: âœ… è‰¯å¥½ï¼æ£€æµ‹å®Œæˆåº¦ {overall_fill_rate:.1f}%")
    else:
        print(f"\nğŸ¯ è¯„ä¼°: âš ï¸  è¾ƒä½ï¼Œæ£€æµ‹å®Œæˆåº¦ {overall_fill_rate:.1f}%")
    
    print("=" * 80)


def run_full_test(api_url: str, base_url: str, total_batches: int = 5, 
                  workorders_per_batch: int = 20, token: str = None, 
                  monitor: bool = True):
    """è¿è¡Œå®Œæ•´æµç¨‹æµ‹è¯•"""
    print("=" * 80)
    print("ğŸš€ å®Œæ•´æµç¨‹æµ‹è¯•ï¼šä¸Šä¼  â†’ å…¥åº“ â†’ AIæ£€æµ‹ â†’ ç»“æœéªŒè¯")
    print("=" * 80)
    print(f"ğŸ“Š é…ç½®: {total_batches}æ‰¹æ¬¡ Ã— {workorders_per_batch}å·¥å• = {total_batches * workorders_per_batch}æ¡æ•°æ®")
    print(f"ğŸ” æ£€æµ‹ç›‘æ§: {'å·²å¯ç”¨' if monitor else 'å·²ç¦ç”¨'}")
    print("=" * 80)
    print()
    
    # ç¬¬ä¸€é˜¶æ®µï¼šä¸Šä¼ æ•°æ®
    print("ğŸ“¤ ç¬¬ä¸€é˜¶æ®µï¼šæ‰¹é‡ä¸Šä¼ æ•°æ®")
    print("-" * 80)
    
    success_count = 0
    failed_count = 0
    uploaded_batches = []
    
    for i in range(total_batches):
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
        random_suffix = random.randint(1000, 9999)
        batch_id = f"test_{timestamp}_{random_suffix}"
        
        success, elapsed, result, bid = upload_batch(api_url, batch_id, workorders_per_batch, token)
        if success:
            success_count += 1
            uploaded_batches.append(batch_id)
        else:
            failed_count += 1
        
        time.sleep(0.5)  # æ‰¹æ¬¡é—´å»¶è¿Ÿ
    
    print(f"\nâœ… ä¸Šä¼ å®Œæˆ: æˆåŠŸ{success_count}, å¤±è´¥{failed_count}")
    
    # ç¬¬äºŒé˜¶æ®µï¼šç›‘æ§æ£€æµ‹
    if monitor and uploaded_batches:
        time.sleep(2)  # ç­‰å¾…2ç§’è®©é˜Ÿåˆ—å¼€å§‹å¤„ç†
        monitor_detection(uploaded_batches, base_url, token)
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")


if __name__ == '__main__':
    # é…ç½®
    BASE_URL = "http://localhost:5000"
    API_URL = f"{BASE_URL}/excel/quality-dataupload"
    OAUTH_TOKEN = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJjbGllbnRfaWQiOiJhcGlfdGVzdF9jbGllbnRfdG9tYXRvIiwic2NvcGVzIjpbIioiXSwiZXhwIjoxNzY1ODczODIxLCJpYXQiOjE3NjUyNjkwMjEsInR5cGUiOiJhY2Nlc3NfdG9rZW4ifQ.V9r_NiRtEBmnBKgeUr-t0VsUIxNn7E3ouYbOYO4q3Ic"
    
    print("è¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. å¿«é€Ÿæµ‹è¯• (5æ‰¹æ¬¡ Ã— 10å·¥å• = 50æ¡ï¼Œå«æ£€æµ‹ç›‘æ§)")
    print("2. æ ‡å‡†æµ‹è¯• (10æ‰¹æ¬¡ Ã— 20å·¥å• = 200æ¡ï¼Œå«æ£€æµ‹ç›‘æ§)")
    print("3. å‹åŠ›æµ‹è¯• (20æ‰¹æ¬¡ Ã— 50å·¥å• = 1000æ¡ï¼Œå«æ£€æµ‹ç›‘æ§)")
    print("4. ä»…ä¸Šä¼ æµ‹è¯• (ä¸ç›‘æ§æ£€æµ‹)")
    
    choice = input("\nè¯·é€‰æ‹© (1-4ï¼Œé»˜è®¤1): ").strip() or '1'
    
    scenarios = {
        '1': {'batches': 5, 'workorders': 10, 'monitor': True},
        '2': {'batches': 10, 'workorders': 20, 'monitor': True},
        '3': {'batches': 20, 'workorders': 50, 'monitor': True},
        '4': {'batches': 10, 'workorders': 20, 'monitor': False}
    }
    
    config = scenarios.get(choice, scenarios['1'])
    
    print(f"\nâ³ 3ç§’åå¼€å§‹æµ‹è¯•...\n")
    time.sleep(3)
    
    run_full_test(
        API_URL,
        BASE_URL,
        total_batches=config['batches'],
        workorders_per_batch=config['workorders'],
        token=OAUTH_TOKEN,
        monitor=config['monitor']
    )
