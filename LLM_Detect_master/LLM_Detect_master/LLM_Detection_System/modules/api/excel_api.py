#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è´¨é‡å·¥å•æ£€æµ‹ API è·¯ç”±
æä¾›RESTful APIæ¥å£ä¾›å¤–éƒ¨è°ƒç”¨
"""

import os
import time
from flask import Blueprint, request, jsonify, current_app, g
from werkzeug.utils import secure_filename
from modules.auth.oauth_utils import require_oauth
from modules.excel.models import WorkorderData, WorkorderUselessdata1, WorkorderUselessdata2
from modules.excel.queue_manager import get_queue_manager
from modules.auth import db
import pandas as pd

# åˆ›å»ºExcel APIè“å›¾
excel_api_bp = Blueprint('excel_api', __name__)


def allowed_excel_file(filename):
    """æ£€æŸ¥æ–‡ä»¶ç±»å‹æ˜¯å¦å…è®¸"""
    ALLOWED_EXTENSIONS = {'xlsx', 'xls'}
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


@excel_api_bp.route('/upload', methods=['POST'])
@require_oauth(['excel:upload'])
def api_upload_excel():
    """API: ä¸Šä¼ è´¨é‡å·¥å•Excelæ–‡ä»¶ï¼ˆä¸Šä¼ åè‡ªåŠ¨åŠ å…¥æ£€æµ‹é˜Ÿåˆ—ï¼‰

    è¯·æ±‚æ ¼å¼:
        POST /api/v1/excel/upload
        Authorization: Bearer <access_token>
        Content-Type: multipart/form-data

        file: Excelæ–‡ä»¶ (å¿…å¡«)
        batch_size: æ‰¹é‡å¤„ç†å¤§å°ï¼Œé»˜è®¤50 (å¯é€‰)

    å“åº”æ ¼å¼:
        {
            "success": true,
            "task_id": "20251201_120000_workorder.xlsx",
            "filename": "workorder.xlsx",
            "rows_count": 100,
            "status": "pending",
            "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ£€æµ‹ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—"
        }
    """
    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if 'file' not in request.files:
        return jsonify({
            'error': 'missing_file',
            'error_description': 'è¯·æ±‚ä¸­æ²¡æœ‰æ–‡ä»¶'
        }), 400

    file = request.files['file']

    # 2. æ£€æŸ¥æ–‡ä»¶å
    if file.filename == '':
        return jsonify({
            'error': 'empty_filename',
            'error_description': 'æ–‡ä»¶åä¸ºç©º'
        }), 400

    # 3. æ£€æŸ¥æ–‡ä»¶ç±»å‹
    if not allowed_excel_file(file.filename):
        return jsonify({
            'error': 'invalid_file_type',
            'error_description': 'åªæ”¯æŒExcelæ ¼å¼æ–‡ä»¶(.xlsx, .xls)'
        }), 400

    # 4. è·å–æ‰¹é‡å¤„ç†å‚æ•°å’Œç”¨æˆ·ä¿¡æ¯
    batch_size = request.form.get('batch_size', 50, type=int)
    if batch_size < 1 or batch_size > 200:
        return jsonify({
            'error': 'invalid_batch_size',
            'error_description': 'æ‰¹é‡å¤„ç†å¤§å°å¿…é¡»åœ¨1-200ä¹‹é—´'
        }), 400
    
    # è·å–accountå’Œdatatimeï¼ˆAPIè°ƒç”¨æ—¶å¿…é¡»æä¾›ï¼‰
    account = request.form.get('account', '').strip()
    datatime_client = request.form.get('datatime', '').strip()
    
    if not account:
        return jsonify({
            'error': 'missing_account',
            'error_description': 'ç¼ºå°‘accountå‚æ•°'
        }), 400
    
    # datatime ç»Ÿä¸€ä½¿ç”¨æœåŠ¡å™¨å½“å‰æ—¶é—´ï¼Œé¿å…å®¢æˆ·ç«¯ä¼ å›ºå®šå€¼å¯¼è‡´å†™å…¥è¿‡æœŸæ—¶é—´
    datatime = time.strftime('%Y-%m-%d %H:%M:%S')
    if datatime_client:
        print(f"â„¹ï¸ [API] å·²å¿½ç•¥å®¢æˆ·ç«¯ datatime={datatime_client}ï¼Œä½¿ç”¨æœåŠ¡å™¨å½“å‰æ—¶é—´: {datatime}")
    else:
        print(f"â„¹ï¸ [API] datatime æœªæä¾›ï¼Œä½¿ç”¨æœåŠ¡å™¨å½“å‰æ—¶é—´: {datatime}")
    
    print(f"ğŸ“‹ [API] è´¦å·: {account}, æ—¶é—´: {datatime}")

    # 5. ä¿å­˜æ–‡ä»¶å¹¶è§£ææ•°æ®
    try:
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        timestamp_str = time.strftime('%Y%m%d_%H%M%S')
        original_filename = os.path.basename(file.filename)
        unique_filename = f"{timestamp_str}_{original_filename}"

        # ä¿å­˜åˆ°uploadsç›®å½•
        upload_folder = current_app.config['UPLOAD_FOLDER']
        filepath = os.path.join(upload_folder, unique_filename)
        file.save(filepath)

        print(f"âœ… [API] æ–‡ä»¶å·²ä¿å­˜: {filepath}")

        # 6. è§£æExcelæ–‡ä»¶
        try:
            df = pd.read_excel(filepath, dtype=str)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæ–‡ä»¶
            if df.empty:
                os.remove(filepath)  # åˆ é™¤æ— æ•ˆæ–‡ä»¶
                return jsonify({
                    'error': 'empty_file',
                    'error_description': 'Excelæ–‡ä»¶ä¸ºç©º'
                }), 400

            rows_count = len(df)
            print(f"ğŸ“Š [API] Excelæ–‡ä»¶åŒ…å« {rows_count} è¡Œæ•°æ®")

            # æ£€æŸ¥å¿…è¦å­—æ®µï¼ˆ83ä¸ªå­—æ®µçš„Excelï¼‰
            required_columns = ['å·¥å•å•å·', 'å·¥å•æ€§è´¨', 'åˆ¤å®šä¾æ®']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                os.remove(filepath)  # åˆ é™¤æ— æ•ˆæ–‡ä»¶
                return jsonify({
                    'error': 'invalid_format',
                    'error_description': f'Excelæ–‡ä»¶ç¼ºå°‘å¿…è¦å­—æ®µ: {", ".join(missing_columns)}'
                }), 400

        except Exception as e:
            os.remove(filepath)  # åˆ é™¤æ— æ•ˆæ–‡ä»¶
            return jsonify({
                'error': 'parse_failed',
                'error_description': f'è§£æExcelæ–‡ä»¶å¤±è´¥: {str(e)}'
            }), 400

        # 7. å°†æ•°æ®æ’å…¥æ•°æ®åº“ï¼ˆä¸‰ä¸ªè¡¨ï¼‰
        try:
            from modules.excel.field_mapping import (
                get_workorder_data_mapping,
                get_workorder_uselessdata_1_mapping,
                get_workorder_uselessdata_2_mapping
            )

            # è·å–å­—æ®µæ˜ å°„
            data_fields = get_workorder_data_mapping()
            useless1_fields = get_workorder_uselessdata_1_mapping()
            useless2_fields = get_workorder_uselessdata_2_mapping()

            # æ’å…¥WorkorderDataè¡¨
            for _, row in df.iterrows():
                work_alone = str(row.get('å·¥å•å•å·', '')).strip()
                if not work_alone or work_alone == 'nan':
                    continue

                # å‡†å¤‡WorkorderDataæ•°æ®
                data_record = WorkorderData(
                    filename=unique_filename,
                    workAlone=work_alone,
                    workOrderNature=None,  # æ£€æµ‹å‰ä¸ºç©º
                    judgmentBasis=None,    # æ£€æµ‹å‰ä¸ºç©º
                    account=account,       # APIè°ƒç”¨è€…æä¾›çš„è´¦å·
                    datatime=datatime      # APIè°ƒç”¨æ—¶çš„æ—¶é—´æˆ³
                )

                # æ˜ å°„å…¶ä»–å­—æ®µ
                for excel_col, db_field in data_fields.items():
                    if excel_col in df.columns and db_field not in ['workAlone', 'workOrderNature', 'judgmentBasis', 'filename', 'account', 'datatime']:
                        value = row.get(excel_col)
                        if pd.notna(value):
                            setattr(data_record, db_field, str(value))

                db.session.add(data_record)

                # å‡†å¤‡WorkorderUselessdata1æ•°æ®
                useless1_record = WorkorderUselessdata1(
                    filename=unique_filename,
                    workAlone=work_alone
                )
                for excel_col, db_field in useless1_fields.items():
                    if excel_col in df.columns and db_field not in ['workAlone', 'filename']:
                        value = row.get(excel_col)
                        if pd.notna(value):
                            setattr(useless1_record, db_field, str(value))

                db.session.add(useless1_record)

                # å‡†å¤‡WorkorderUselessdata2æ•°æ®
                useless2_record = WorkorderUselessdata2(
                    filename=unique_filename,
                    workAlone=work_alone
                )
                for excel_col, db_field in useless2_fields.items():
                    if excel_col in df.columns and db_field not in ['workAlone', 'filename']:
                        value = row.get(excel_col)
                        if pd.notna(value):
                            setattr(useless2_record, db_field, str(value))

                db.session.add(useless2_record)

            # æäº¤æ•°æ®åº“äº‹åŠ¡
            db.session.commit()
            print(f"ğŸ’¾ [API] æ•°æ®å·²æ’å…¥æ•°æ®åº“: {rows_count} æ¡è®°å½•")

        except Exception as e:
            db.session.rollback()
            os.remove(filepath)  # åˆ é™¤æ–‡ä»¶
            return jsonify({
                'error': 'database_error',
                'error_description': f'æ•°æ®å…¥åº“å¤±è´¥: {str(e)}'
            }), 500

        # 8. å°†æ£€æµ‹ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—
        queue_manager = get_queue_manager(current_app)
        queue_added = queue_manager.add_task(
            filename=unique_filename,
            filepath=filepath,
            batch_size=batch_size
        )

        if not queue_added:
            return jsonify({
                'error': 'queue_failed',
                'error_description': 'ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—å¤±è´¥ï¼Œè¯·é‡è¯•'
            }), 500

        print(f"âœ… [API] æ£€æµ‹ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—: {unique_filename}")

        # 9. è¿”å›æˆåŠŸå“åº”
        return jsonify({
            'success': True,
            'task_id': unique_filename,
            'filename': original_filename,
            'rows_count': rows_count,
            'batch_size': batch_size,
            'status': 'pending',
            'message': 'æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ£€æµ‹ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—'
        }), 200

    except Exception as e:
        if os.path.exists(filepath):
            os.remove(filepath)
        return jsonify({
            'error': 'upload_failed',
            'error_description': f'æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}'
        }), 500


@excel_api_bp.route('/status/<task_id>', methods=['GET'])
@require_oauth(['excel:query'])
def api_get_excel_status(task_id):
    """API: æŸ¥è¯¢æ£€æµ‹ä»»åŠ¡çŠ¶æ€

    è¯·æ±‚æ ¼å¼:
        GET /api/v1/excel/status/<task_id>
        Authorization: Bearer <access_token>

    å“åº”æ ¼å¼:
        {
            "success": true,
            "task_id": "20251201_120000_workorder.xlsx",
            "status": "pending|processing|completed|failed",
            "rows_total": 100,
            "rows_processed": 50,
            "progress": 50,
            "result_files": {
                "csv": "quality_result_20251201_120030.csv",
                "excel": "quality_result_20251201_120030.xlsx"
            }
        }
    """
    try:
        # è·å–é˜Ÿåˆ—ç®¡ç†å™¨
        queue_manager = get_queue_manager(current_app)
        
        # æŸ¥è¯¢é˜Ÿåˆ—çŠ¶æ€
        task_status = queue_manager.get_task_status(task_id)
        
        # æŸ¥è¯¢æ•°æ®åº“è®°å½•
        records = WorkorderData.query.filter_by(filename=task_id).all()
        
        if not records:
            return jsonify({
                'error': 'task_not_found',
                'error_description': 'ä»»åŠ¡ä¸å­˜åœ¨'
            }), 404

        rows_total = len(records)
        rows_processed = sum(1 for r in records if r.workOrderNature)

        # æ„å»ºå“åº”æ•°æ®
        response = {
            'success': True,
            'task_id': task_id,
            'status': task_status or 'unknown',
            'rows_total': rows_total,
            'rows_processed': rows_processed,
            'progress': int((rows_processed / rows_total * 100) if rows_total > 0 else 0)
        }

        # æ ¹æ®çŠ¶æ€æ·»åŠ ä¸åŒçš„å­—æ®µ
        if task_status == 'completed':
            # æŸ¥è¯¢ç»“æœæ–‡ä»¶
            task_result = queue_manager.get_task_result(task_id)
            if task_result:
                response['result_files'] = {
                    'csv': task_result.get('csv_filename'),
                    'excel': task_result.get('excel_filename')
                }
                response['message'] = 'æ£€æµ‹å®Œæˆ'
        elif task_status == 'processing':
            response['message'] = 'æ­£åœ¨æ£€æµ‹ä¸­ï¼Œè¯·ç¨å€™...'
        elif task_status == 'pending':
            queue_info = queue_manager.get_queue_info()
            response['queue_size'] = queue_info['queue_size']
            response['message'] = 'ä»»åŠ¡æ’é˜Ÿä¸­ï¼Œè¯·ç¨å€™...'
        elif task_status == 'failed':
            response['message'] = 'æ£€æµ‹å¤±è´¥ï¼Œè¯·é‡æ–°ä¸Šä¼ '

        return jsonify(response), 200

    except Exception as e:
        return jsonify({
            'error': 'query_failed',
            'error_description': f'æŸ¥è¯¢çŠ¶æ€å¤±è´¥: {str(e)}'
        }), 500


@excel_api_bp.route('/result/<task_id>', methods=['GET'])
@require_oauth(['excel:query'])
def api_get_excel_result(task_id):
    """API: è·å–æ£€æµ‹ç»“æœæ•°æ®

    è¯·æ±‚æ ¼å¼:
        GET /api/v1/excel/result/<task_id>
        Authorization: Bearer <access_token>

    å“åº”æ ¼å¼:
        {
            "success": true,
            "task_id": "20251201_120000_workorder.xlsx",
            "rows_total": 100,
            "results": [
                {
                    "å·¥å•å•å·": "WO001",
                    "å·¥å•æ€§è´¨": "è´¨é‡é—®é¢˜",
                    "åˆ¤å®šä¾æ®": "æ ¹æ®...",
                    ...
                }
            ]
        }
    """
    try:
        # æŸ¥è¯¢æ•°æ®åº“è®°å½•
        records = WorkorderData.query.filter_by(filename=task_id).all()

        if not records:
            return jsonify({
                'error': 'task_not_found',
                'error_description': 'ä»»åŠ¡ä¸å­˜åœ¨'
            }), 404

        # æ„å»º19å­—æ®µç»“æœæ•°æ®
        expected_columns = ['å·¥å•å•å·','å·¥å•æ€§è´¨','åˆ¤å®šä¾æ®','ä¿å†…ä¿å¤–','æ‰¹æ¬¡å…¥åº“æ—¥æœŸ','å®‰è£…æ—¥æœŸ','è´­æœºæ—¥æœŸ',
                          'äº§å“åç§°','å¼€å‘ä¸»ä½“','æ•…éšœéƒ¨ä½åç§°','æ•…éšœç»„','æ•…éšœç±»åˆ«','æœåŠ¡é¡¹ç›®æˆ–æ•…éšœç°è±¡',
                          'ç»´ä¿®æ–¹å¼','æ—§ä»¶åç§°','æ–°ä»¶åç§°','æ¥ç”µå†…å®¹','ç°åœºè¯Šæ–­æ•…éšœç°è±¡','å¤„ç†æ–¹æ¡ˆç®€è¿°æˆ–å¤‡æ³¨']

        results = []
        for record in records:
            u1 = WorkorderUselessdata1.query.filter_by(filename=task_id, workAlone=record.workAlone).first()
            u2 = WorkorderUselessdata2.query.filter_by(filename=task_id, workAlone=record.workAlone).first()

            def norm(v):
                return '' if v is None or v == 'None' or (isinstance(v, float) and pd.isna(v)) else str(v)

            row_data = {
                'å·¥å•å•å·': norm(record.workAlone),
                'å·¥å•æ€§è´¨': norm(record.workOrderNature),
                'åˆ¤å®šä¾æ®': norm(record.judgmentBasis),
                'ä¿å†…ä¿å¤–': norm(u1.internalExternalInsurance if u1 else ''),
                'æ‰¹æ¬¡å…¥åº“æ—¥æœŸ': norm(u1.batchWarehousingDate if u1 else ''),
                'å®‰è£…æ—¥æœŸ': norm(u1.installDate if u1 else ''),
                'è´­æœºæ—¥æœŸ': norm(u1.purchaseDate if u1 else ''),
                'äº§å“åç§°': norm(u1.productName if u1 else ''),
                'å¼€å‘ä¸»ä½“': norm(u1.developmentSubject if u1 else ''),
                'æ•…éšœéƒ¨ä½åç§°': norm(record.replacementPartName),
                'æ•…éšœç»„': norm(record.faultGroup),
                'æ•…éšœç±»åˆ«': norm(record.faultClassification),
                'æœåŠ¡é¡¹ç›®æˆ–æ•…éšœç°è±¡': norm(record.faultPhenomenon),
                'ç»´ä¿®æ–¹å¼': norm(u2.maintenanceMode if u2 else ''),
                'æ—§ä»¶åç§°': norm(u2.oldPartName if u2 else ''),
                'æ–°ä»¶åç§°': norm(u2.newPartName if u2 else ''),
                'æ¥ç”µå†…å®¹': norm(record.callContent),
                'ç°åœºè¯Šæ–­æ•…éšœç°è±¡': norm(record.onsiteFaultPhenomenon),
                'å¤„ç†æ–¹æ¡ˆç®€è¿°æˆ–å¤‡æ³¨': norm(record.remarks),
            }
            results.append(row_data)

        return jsonify({
            'success': True,
            'task_id': task_id,
            'rows_total': len(results),
            'columns': expected_columns,
            'results': results
        }), 200

    except Exception as e:
        return jsonify({
            'error': 'query_failed',
            'error_description': f'æŸ¥è¯¢ç»“æœå¤±è´¥: {str(e)}'
        }), 500


@excel_api_bp.route('/download/<task_id>', methods=['GET'])
@require_oauth(['excel:query'])
def api_download_excel_result(task_id):
    """API: ä¸‹è½½æ£€æµ‹ç»“æœæ–‡ä»¶

    è¯·æ±‚æ ¼å¼:
        GET /api/v1/excel/download/<task_id>?format=excel
        Authorization: Bearer <access_token>
        
        å‚æ•°:
            format: excel æˆ– csvï¼Œé»˜è®¤ excel

    å“åº”:
        è¿”å›æ–‡ä»¶æµ
    """
    try:
        # è·å–é˜Ÿåˆ—ç®¡ç†å™¨
        queue_manager = get_queue_manager(current_app)
        
        # æŸ¥è¯¢ç»“æœæ–‡ä»¶
        task_result = queue_manager.get_task_result(task_id)
        
        if not task_result:
            return jsonify({
                'error': 'result_not_found',
                'error_description': 'ç»“æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ£€æµ‹å¯èƒ½æœªå®Œæˆ'
            }), 404

        # è·å–æ–‡ä»¶æ ¼å¼
        file_format = request.args.get('format', 'excel')
        
        if file_format == 'csv':
            filename = task_result.get('csv_filename')
        else:
            filename = task_result.get('excel_filename')

        if not filename:
            return jsonify({
                'error': 'file_not_found',
                'error_description': 'ç»“æœæ–‡ä»¶ä¸å­˜åœ¨'
            }), 404

        # æ„å»ºæ–‡ä»¶è·¯å¾„
        results_folder = current_app.config['RESULTS_FOLDER']
        filepath = os.path.join(results_folder, filename)

        if not os.path.exists(filepath):
            return jsonify({
                'error': 'file_not_found',
                'error_description': 'ç»“æœæ–‡ä»¶ä¸å­˜åœ¨'
            }), 404

        # è¿”å›æ–‡ä»¶
        from flask import send_file
        return send_file(
            filepath,
            as_attachment=True,
            download_name=filename
        )

    except Exception as e:
        return jsonify({
            'error': 'download_failed',
            'error_description': f'ä¸‹è½½å¤±è´¥: {str(e)}'
        }), 500


@excel_api_bp.route('/health', methods=['GET'])
def api_health_check():
    """API: å¥åº·æ£€æŸ¥ï¼ˆæ— éœ€è®¤è¯ï¼‰

    è¯·æ±‚æ ¼å¼:
        GET /api/v1/excel/health

    å“åº”æ ¼å¼:
        {
            "status": "ok",
            "service": "Excel Quality Inspection API",
            "version": "1.0.0"
        }
    """
    return jsonify({
        'status': 'ok',
        'service': 'Excel Quality Inspection API',
        'version': '1.0.0'
    }), 200
